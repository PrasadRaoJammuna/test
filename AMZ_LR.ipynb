{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMZ_LR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrasadRaoJammuna/test/blob/master/AMZ_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_fesEkNmOfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc,accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from prettytable import PrettyTable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-qfHqvjqX1I",
        "colab_type": "code",
        "outputId": "efdd255d-9f22-4aec-e422-6508bd7bc6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "source": [
        "amz = pd.read_csv('Reviews.csv')\n",
        "amz.head(1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-24e5896b2ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mamz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mamz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 73048"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKGzbhYcrMfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amz.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnJ3__cJrOx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amz=amz[amz['Score']!=3]\n",
        "amz.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RmWWdlzrdB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_rate(score):\n",
        "    if score >3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EFPBPG2rnQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_rate(amz['Score'][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSZFJB-rsHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amz['Score'] = amz['Score'].apply(score_rate)\n",
        "amz['Score'].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arGpRoaBr1eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amz.Score.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eZtxr93r7G3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deduplication of entries\n",
        "amz=amz.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
        "amz.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdzqtxUfsC9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amz=amz[amz.HelpfulnessNumerator<=amz.HelpfulnessDenominator]\n",
        "amz.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvYZy3VvsRpv",
        "colab_type": "text"
      },
      "source": [
        "###Preprocessing Review Text\n",
        "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n",
        "\n",
        "Hence in the Preprocessing phase we do the following in the order below:-\n",
        "\n",
        "Remove any punctuations or limited set of special characters like , or . or # etc.\n",
        "Begin by removing the html tags\n",
        "Check if the word is made up of english letters and is not alpha-numeric\n",
        "Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
        "Convert the word to lowercase\n",
        "Remove Stopwords\n",
        "Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)\n",
        "After which we collect the words used to describe positive and negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ1aqQJ3sJlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# printing some random reviews\n",
        "sent_0 = amz['Text'].values[0]\n",
        "print(sent_0)\n",
        "print(\"=\"*50)\n",
        "\n",
        "sent_1000 = amz['Text'].values[1000]\n",
        "print(sent_1000)\n",
        "print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q328aGA2sd3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0Gp1ng_skHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_1000 = decontracted(sent_1000)\n",
        "print(sent_1000)\n",
        "print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oPu31eisvqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
        "# we are including them into stop words list\n",
        "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNZA_nGDs0oO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pos = amz[amz['Score']==1].head(50000).sample(5000,random_state=100)\n",
        "df_pos.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UA-7Lw_s92N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_neg = amz[amz['Score']==0].tail(10000).sample(5575,random_state=1000)\n",
        "df_neg.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gbmUi1QtLMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([df_neg,df_pos])\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PWQcBJBtS2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Score.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCpzgMNbtWc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLN256b_tZ5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combining all the above stundents \n",
        "from tqdm import tqdm\n",
        "preprocessed_reviews = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df['Text'].values):\n",
        "    sentance = re.sub(r\"http\\S+\", \" \", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = decontracted(sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    # https://gist.github.com/sebleier/554280\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
        "\n",
        "\n",
        "    preprocessed_reviews.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191PcLmvtfsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(preprocessed_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqIbPm6ouoeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_reviews[89]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XzRFxUcvgDo",
        "colab_type": "text"
      },
      "source": [
        "# Applying Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx3shTOsvmbT",
        "colab_type": "text"
      },
      "source": [
        "## [1.1] Logistic Regression on BOW, SET 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6zXGxNWwSOp",
        "colab_type": "text"
      },
      "source": [
        "### [1.1.1] Applying Logistic Regression with L1 regularization on BOW, SET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgnO4OlmusHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_vect = CountVectorizer()\n",
        "bow_words = bow_vect.fit_transform(preprocessed_reviews).toarray()\n",
        "\n",
        "print(\"shape of bow\",bow_words.shape)\n",
        "print()\n",
        "print(\"some feature names:\",bow_vect.get_feature_names()[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gP1DI3Yw28W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = bow_words\n",
        "print(type(x))\n",
        "print(x.shape)\n",
        "y = np.array(df['Score'])\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd1xEuECLr8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOCeJ1lQMCgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scalar  = StandardScaler()\n",
        "x = scalar.fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvV8XZdDMVNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cOLLSGixZRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgiCsxnDxpT7",
        "colab_type": "text"
      },
      "source": [
        "#### simple Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlwVdtEexlnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_tr,x_cv,y_tr,y_cv = train_test_split(x_train,y_train,test_size=0.2,random_state=786)\n",
        "\n",
        "auc_scores_cv=[]\n",
        "auc_scores_tr = []\n",
        "\n",
        "lam =[0.0001,0.001,0.01,0.1,1.0,10,100,1000]\n",
        "\n",
        "for i in lam:\n",
        "    lr_bow = LogisticRegression(C=i,penalty='l1')\n",
        "    lr_bow.fit(x_tr,y_tr)\n",
        "    pred_cv= lr_bow.predict(x_cv)\n",
        "    pred_tr= lr_bow.predict(x_tr)\n",
        "     \n",
        "    fpr_cv, tpr_cv, thresholds_cv = roc_curve(y_cv, pred_cv)\n",
        "    auc_score_cv = auc(fpr_cv, tpr_cv)\n",
        "    \n",
        "    fpr_tr, tpr_tr, thresholds_tr = roc_curve(y_tr, pred_tr)\n",
        "    auc_score_tr = auc(fpr_tr, tpr_tr)\n",
        "    \n",
        "    \n",
        "    auc_scores_cv.append((auc_score_cv,i))\n",
        "    auc_scores_tr.append((auc_score_tr,i))\n",
        "    \n",
        "    print(\"\\nCV Accuracy for  (Î±)={} is {:.2f}\".format(i,auc_score_cv))\n",
        "    \n",
        "print(10*'===')\n",
        "print(\"Best accuracy:\",max(auc_scores_cv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb0THPwL0xTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=[]\n",
        "s =[]\n",
        "for i,j in auc_scores_cv:\n",
        "    a.append(j)\n",
        "    s.append(i)\n",
        "    \n",
        "k =[]\n",
        "l=[]\n",
        "\n",
        "for i,j in auc_scores_tr:\n",
        "    k.append(j)\n",
        "    l.append(i)\n",
        "    \n",
        "plt.figure(figsize=(8,5))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.plot(a,s)\n",
        "plt.plot(k,l)\n",
        "#plt.xlim([-0.0001,1000])\n",
        "plt.xlabel(\"Lambda-values\")\n",
        "plt.ylabel('AUC scores')\n",
        "plt.show()\n",
        "\n",
        "print(\"Best Lambda-CrossValidation:\",max(auc_scores_cv)[1])\n",
        "#print(\"Best Lambda-Tr data:\",max(auc_scores_tr)[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meF2_HQ_3Cnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu8NBDjQ3qtL",
        "colab_type": "text"
      },
      "source": [
        "#### GridiSearchCv with BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfbthYEr3s3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lam =[0.1,1.0,10,100,1000]\n",
        "param_grid=dict(C=lam)\n",
        "print(param_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nAngWZz3-Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_lr_bow = GridSearchCV(lr_bow, param_grid=param_grid,cv=3,scoring='roc_auc')\n",
        "grid_lr_bow.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW4iMkfD4Kyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best Estimators:\",grid_lr_bow.best_estimator_)\n",
        "print(\"Best lambda:\",grid_lr_bow.best_params_)\n",
        "print(\"Bset Roc-AUC score:\",grid_lr_bow.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umgl1TrV5eS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_bow = LogisticRegression(penalty='l1',C=grid_lr_bow.best_params_['C'])\n",
        "lr_bow.fit(x_train,y_train)\n",
        "y_pred_bow = lr_bow.predict(x_test)\n",
        "y_pred_train_bow = lr_bow.predict(x_train)\n",
        "print(\"Accuracy on Test Data:\",accuracy_score(y_pred_bow,y_test)*100)\n",
        "print(\"Accuracy on Train Data:\",accuracy_score(y_pred_train_bow,y_train)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsFeFyUu6lbh",
        "colab_type": "text"
      },
      "source": [
        "#### AUC SCore on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6SZem_253HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr_test_bow, tpr_test_bow, thresholds = roc_curve(y_pred_bow, y_test)\n",
        "auc_score_test_bow= auc(fpr_test_bow, tpr_test_bow)\n",
        "print(\"AUC Score on Test data:\",(auc_score_test_bow)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDQLuKeL6wX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc_test_bow = roc_auc_score(y_test,y_pred_bow)\n",
        "fpr_test_bow,tpr_test_bow,thersholds_test = roc_curve(y_test,lr_bow.predict_proba(x_test)[:,1])\n",
        "\n",
        "roc_auc_train_bow = roc_auc_score(y_train,y_pred_train_bow)\n",
        "fpr_train,tpr_train,thersholds_train = roc_curve(y_train,lr_bow.predict_proba(x_train)[:,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gdWqR1g63Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.style.use('classic')\n",
        "plt.plot(fpr_test_bow,tpr_test_bow,label='Model_LR with Test Data (area = %.2f).'% roc_auc_test_bow)\n",
        "plt.plot(fpr_train,tpr_train,label='Model_LR with Train Data (area = %.2f).'% roc_auc_train_bow)\n",
        "plt.plot([0,1],[0,1])\n",
        "plt.xlim([-0.05,1.05])\n",
        "plt.ylim([-0.05,1.05])\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"RoC -AUC curve Model-1\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aybuc6zGFGZS",
        "colab_type": "text"
      },
      "source": [
        "#### confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOdQ-_6e7XFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred_bow)\n",
        "\n",
        "class_label = [\"negative\", \"positive\"]\n",
        "df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(df_cm, annot = True,cbar=False,fmt = \"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDTMiwbYBbul",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6ozJMZBBbqr",
        "colab_type": "text"
      },
      "source": [
        "#### [11.1.1] Calculating sparsity on weight vector obtained using L1 regularization on BOW, SET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCC38qMWAv7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = lr_bow.coef_\n",
        "print(\" sparsity on weight vector obtained using L1 regularization on BOW \",np.count_nonzero(w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTDuNQaIB-Sq",
        "colab_type": "text"
      },
      "source": [
        "### [1.1.2] Applying Logistic Regression with L2 regularization on BOW, SET 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo_qthKXC2LL",
        "colab_type": "text"
      },
      "source": [
        "#### gridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ROwdWY7BT3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lam =[0.001,0.01,0.1,1.0,10,100,1000]\n",
        "param_grid=dict(C=lam)\n",
        "print(param_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1fsczGDKek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_bow = LogisticRegression(penalty='l2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FVEmaE2DBtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_lr_bow = GridSearchCV(lr_bow, param_grid=param_grid,cv=3,scoring='f1')\n",
        "grid_lr_bow.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_6SNbTqDXcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Best Estimators:\",grid_lr_bow.best_estimator_)\n",
        "print(\"Best lambda:\",grid_lr_bow.best_params_)\n",
        "print(\"Bset f1- score:\",grid_lr_bow.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju9P7aciDlCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_bow = LogisticRegression(penalty='l2',C=grid_lr_bow.best_params_['C'])\n",
        "lr_bow.fit(x_train,y_train)\n",
        "y_pred_bow = lr_bow.predict(x_test)\n",
        "y_pred_train_bow = lr_bow.predict(x_train)\n",
        "print(\"Accuracy on Test Data:\",accuracy_score(y_pred_bow,y_test)*100)\n",
        "print(\"Accuracy on Train Data:\",accuracy_score(y_pred_train_bow,y_train)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2zIXCM3EZYq",
        "colab_type": "text"
      },
      "source": [
        "#### AUC roc Curve-model comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPnNuP0sDuIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc_test_bow_l2 = roc_auc_score(y_test,y_pred_bow)\n",
        "fpr_test_bow_l2,tpr_test_bow_l2,thersholds_test = roc_curve(y_test,lr_bow.predict_proba(x_test)[:,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCu5cXOUEOd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.style.use('classic')\n",
        "plt.plot(fpr_test_bow,tpr_test_bow,label='Model_LR with Test Data-L1 (area = %.2f).'% roc_auc_test_bow)\n",
        "plt.plot(fpr_test_bow_l2,tpr_test_bow_l2,label='Model_LR with Test Data -L2(area = %.2f).'% roc_auc_test_bow_l2)\n",
        "plt.plot([0,1],[0,1])\n",
        "plt.xlim([-0.05,1.05])\n",
        "plt.ylim([-0.05,1.05])\n",
        "plt.legend(loc=0)\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(\"RoC -AUC curve Model-1\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZhVraSXFNZG",
        "colab_type": "text"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t4c_i3xE_Dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(y_test,y_pred_bow)\n",
        "\n",
        "class_label = [\"negative\", \"positive\"]\n",
        "df_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(df_cm, annot = True,cbar=False,fmt = \"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BqI2Sy-FRmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHMotx63FuJ6",
        "colab_type": "text"
      },
      "source": [
        "#### [1.1.2.1] Performing pertubation test (multicollinearity check) on BOW, SET 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqK9AaOVFx3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_bow_x = LogisticRegression(penalty='l2',C=grid_lr_bow.best_params_['C'])\n",
        "lr_bow_x.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXg9oOzfJnmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_bow_x.coef_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGh-7HkxJtTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = lr_bow_x.coef_\n",
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XETTAA5NJ6su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}